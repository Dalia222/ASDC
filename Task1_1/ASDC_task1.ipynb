{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import collections\n",
        "!pip install imantics\n",
        "\n",
        "\n",
        "import imantics\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from scipy.ndimage import label\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D,Concatenate, Dropout, Conv2DTranspose, concatenate, AveragePooling2D,Activation,UpSampling2D,BatchNormalization\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Xt3BwQx6MBh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acba52d-e95f-4fe5-e6fa-ce0088b993fb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imantics in /usr/local/lib/python3.10/dist-packages (0.1.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imantics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from imantics) (4.8.0.76)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from imantics) (4.9.3)\n",
            "Requirement already satisfied: xmljson in /usr/local/lib/python3.10/dist-packages (from imantics) (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Eo5RqrKIL7Jz"
      },
      "outputs": [],
      "source": [
        "#  @title Load the dataset\n",
        "\n",
        "images_path = '/content/drive/MyDrive/ASDC_dataset/images'\n",
        "labels_path = '/content/drive/MyDrive/ASDC_dataset/COCO_Football Pixel.json'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #  @title Load images and masks\n",
        "\n",
        "# image_size = 512\n",
        "# input_image_size = (1920, 1080)\n",
        "\n",
        "# def read_image(path):\n",
        "#     print(f\"Reading image from path: {path}\")\n",
        "#     img = cv2.imread(path)\n",
        "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#     img = cv2.resize(img, (image_size, image_size))\n",
        "#     return img\n",
        "\n",
        "# annote = json.load(open(labels_path))\n",
        "\n",
        "# id_to_images = {image['id']:image['file_name'] for image in annote['images']}\n",
        "\n",
        "# read_image(images_path)"
      ],
      "metadata": {
        "id": "IMIcf7tAmcE9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_files = os.listdir(images_path)\n",
        "\n",
        "# @title images\n",
        "images = np.zeros((len(image_files), image_size, image_size, 3), dtype=np.uint8)\n",
        "\n",
        "for i, image_filename in enumerate(image_files):\n",
        "    cur_image = read_image(os.path.join(images_path, image_filename))\n",
        "    images[i] = cur_image\n"
      ],
      "metadata": {
        "id": "e3-_ibcmnMCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title masks\n",
        "masks = np.zeros((len(image_files), image_size, image_size, 1), dtype=bool)\n",
        "\n",
        "for annotation in annote[\"annotations\"]:\n",
        "    image_id = annotation[\"image_id\"]\n",
        "    segmentation = annotation[\"segmentation\"]\n",
        "\n",
        "    cur_mask = imantics.Polygons(segmentation).mask(*input_image_size).array\n",
        "    cur_mask = np.expand_dims(resize(cur_mask, (image_size, image_size), mode='constant', preserve_range=True), 2)\n",
        "\n",
        "    mask_index = image_id - 1\n",
        "\n",
        "    # Ensure mask_index is within bounds\n",
        "    if 0 <= mask_index < len(image_files):\n",
        "        masks[mask_index] = masks[mask_index] | cur_mask\n",
        "    else:\n",
        "        print(f\"Invalid image_id: {image_id}\")"
      ],
      "metadata": {
        "id": "qD9GO-GXnQqj"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_images = []\n",
        "for i in range(len(masks)):\n",
        "    temp_mask = np.copy(masks[i])\n",
        "    temp_mask = temp_mask.astype(np.uint8)\n",
        "    temp_image = np.copy(images[i])\n",
        "    temp_masked_image = cv2.bitwise_and(temp_image, temp_image, mask=temp_mask)\n",
        "    masked_images.append(temp_masked_image)"
      ],
      "metadata": {
        "id": "Qf0kYXTprvTd"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target color and threshold for each team\n",
        "team_a_color = np.array([129, 239, 252])\n",
        "team_b_color = np.array([170, 25, 50])\n",
        "ref_color = np.array([30, 50, 90])\n",
        "\n",
        "# The distance from the center color for the team\n",
        "distance_a = 60\n",
        "distance_b = 60\n",
        "distance_ref = 30\n",
        "\n",
        "# The team color in the multilass mask\n",
        "class_a_color = 200\n",
        "class_b_color = 150\n",
        "class_ref_color = 40"
      ],
      "metadata": {
        "id": "HYSfoXQHrwei"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create inverted masks\n",
        "inverted_masks = []\n",
        "for i in range(len(masks)):\n",
        "    temp_inv = masks[i].copy()\n",
        "    temp_inv =  temp_inv.astype(np.uint8)\n",
        "    temp_inv[temp_inv == 0 ] = 255\n",
        "    temp_inv[temp_inv == 1 ] = 0\n",
        "    inverted_masks.append(temp_inv)"
      ],
      "metadata": {
        "id": "p6nSLOqVrzLX"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extractTeamColor(image, target_color, threshold, class_color):\n",
        "    # Calculate the euclidean distance between each pixel and the target color\n",
        "    color_distance = np.linalg.norm(image - target_color, axis=2)\n",
        "    # Create a mask to filter pixels close to the target color\n",
        "    color_mask = color_distance < threshold\n",
        "\n",
        "    # Apply the mask to the original image\n",
        "    extracted_image = np.zeros_like(image)\n",
        "    extracted_image[color_mask] = image[color_mask]\n",
        "\n",
        "    # Assign the class color to each channel of the extracted image\n",
        "    for i in range(extracted_image.shape[2]):\n",
        "        extracted_image[..., i][extracted_image[..., i] != 0] = class_color\n",
        "\n",
        "    return extracted_image"
      ],
      "metadata": {
        "id": "oxSTeXVFr1ii"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recolorWithMask(image):\n",
        "    dark_gray = [10, 10, 10]\n",
        "    black = [0, 0, 0]\n",
        "\n",
        "    # Create a mask for black pixels\n",
        "    black_pixels_mask = np.all(image == black, axis=2)\n",
        "\n",
        "    # Create a mask for white pixels\n",
        "    white_pixels_mask = np.all(image == [255, 255, 255], axis=2)\n",
        "\n",
        "    # Apply black color to the black pixels\n",
        "    image[black_pixels_mask] = dark_gray\n",
        "\n",
        "    # Apply black color to the white pixels\n",
        "    image[white_pixels_mask] = black\n",
        "\n",
        "    return image\n",
        "\n",
        "def recolorFinalClassesMask(image):\n",
        "    red = [255, 0, 0]\n",
        "    blue = [0, 0, 255]\n",
        "    green = [0, 255, 0]\n",
        "    black = [0, 0, 0]\n",
        "    yellow = [255, 255, 0]\n",
        "\n",
        "    #-----------------------\n",
        "    team_a = [200, 200, 200]\n",
        "    team_b  =[150, 150, 150]\n",
        "    #ref_color = [40, 40, 40]\n",
        "    #====\n",
        "    comb1 =[94, 94, 94]\n",
        "    '''comb2 = [240, 240, 240]\n",
        "    comb3 = [140, 140, 140]\n",
        "    comb4 = [136, 136, 136]'''\n",
        "\n",
        "    teamA_pixels_mask = np.all(image == team_a, axis=2)\n",
        "    teamB_pixels_mask = np.all(image == team_b, axis=2)\n",
        "    other_pixels_mask = np.all(image == comb1, axis=2)\n",
        "    #otherMask = np.all((image == comb2) or(image == comb1)  , axis=2)\n",
        "\n",
        "    '''colors = [comb1, comb2, comb3, comb4]\n",
        "    combined_mask = np.zeros(image.shape[:2], dtype=bool)\n",
        "\n",
        "    for color in colors:\n",
        "        mask = np.all(image == color, axis=2)\n",
        "        combined_mask = np.logical_or(combined_mask, mask)'''\n",
        "\n",
        "    image[teamA_pixels_mask] = blue\n",
        "    image[teamB_pixels_mask] = red\n",
        "    #image[ref_pixels_mask] = green\n",
        "    image[other_pixels_mask] = black\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "Ma1z7WCLr3_7"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createClassMask(image, team_color):\n",
        "    # Find connected regions\n",
        "    labels, num_features = label(np.any(image != 0, axis=-1))\n",
        "    #print('labels', labels[90])\n",
        "    # Loop through each connected region\n",
        "    for i in range(1, num_features + 1):\n",
        "        mask = (labels == i)\n",
        "        #print('mask', mask.shape)\n",
        "        # Get the colors in the region\n",
        "        region_colors = image[mask]\n",
        "\n",
        "        flat_array = region_colors.flatten()\n",
        "        #print(flat_array)\n",
        "        vals, counts = np.unique(flat_array, return_counts=True)\n",
        "        for val, count in zip(vals, counts):\n",
        "            if val == team_color  and count > 150:\n",
        "                image[mask] = team_color\n",
        "            elif (val == team_color  and count < 150) or len(vals) == 1:\n",
        "                image[mask] = 0\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "eHN14_TJsFsi"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team_a_masks = []\n",
        "team_b_masks = []\n",
        "final_masks = []\n",
        "\n",
        "for i in range(len(masked_images)):\n",
        "    extracted_color_A = extractTeamColor(masked_images[i], team_a_color, distance_a, class_a_color)\n",
        "    new_im_a = extracted_color_A + inverted_masks[i]\n",
        "    recolor_a = recolorWithMask(new_im_a.copy())\n",
        "    team_a_mask = createClassMask(recolor_a.copy(),class_a_color)\n",
        "    team_a_masks.append(team_a_mask)\n",
        "    #----\n",
        "    extracted_color_B = extractTeamColor(masked_images[i], team_b_color, distance_b, class_b_color)\n",
        "    new_im_b = extracted_color_B + inverted_masks[i]\n",
        "    recolor_b = recolorWithMask(new_im_b.copy())\n",
        "    team_b_mask = createClassMask(recolor_b.copy(),class_b_color)\n",
        "    team_b_masks.append(team_b_mask)\n",
        "     #----\n",
        "    '''extracted_color_ref = extractTeamColor(masked_images[i], ref_color, distance_ref, class_ref_color)\n",
        "    new_im_ref = extracted_color_ref + inverted_masks[i]\n",
        "    recolor_ref = recolorWithMask(new_im_ref.copy())\n",
        "    team_ref_mask = createClassMask(recolor_ref.copy(), class_ref_color)'''\n",
        "\n",
        "    final_mask = team_a_mask + team_b_mask # + team_ref_mask\n",
        "    final_masks.append(final_mask)"
      ],
      "metadata": {
        "id": "CznIAavYsLud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_color_c = extractTeamColor(masked_images[0], team_a_color, distance_a, class_a_color)\n",
        "new_im_c = extracted_color_c + inverted_masks[i]\n",
        "recolor_c = recolorWithMask(new_im_c.copy())\n",
        "team_c_mask = createClassMask(recolor_c.copy(),class_a_color)\n",
        "team_c_mask2 =  createClassMask(team_c_mask.copy(),class_a_color)"
      ],
      "metadata": {
        "id": "1LNUD1GrsYDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(masked_images)):\n",
        "    final_masks[i] = recolorFinalClassesMask(final_masks[i] )"
      ],
      "metadata": {
        "id": "Hr8-6qN_shoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(final_masks[0])"
      ],
      "metadata": {
        "id": "atFUkNjSskY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title preprocessing data\n",
        "def encode_rgb_masks(rgb_masks):\n",
        "    gray_masks = np.zeros((rgb_masks.shape[0], rgb_masks.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    # Define color-to-intensity mappings for each class\n",
        "    color_to_intensity = {\n",
        "        (0, 0, 0): 0,\n",
        "        (255, 0, 0): 1,\n",
        "        (0, 0, 255): 2\n",
        "    }\n",
        "    for i in range(rgb_masks.shape[0]):\n",
        "        for j in range(rgb_masks.shape[1]):\n",
        "            color = tuple(rgb_masks[i, j])\n",
        "            gray_masks[i, j] = color_to_intensity.get(color, 0)\n",
        "\n",
        "    return gray_masks"
      ],
      "metadata": {
        "id": "Ef-50jr0soaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Normalization\n",
        "\n",
        "num_classes = 3\n",
        "\n",
        "encoded_masks= []\n",
        "for i in range(len(final_masks)):\n",
        "    encoded_masks.append(encode_rgb_masks(final_masks[i]))\n",
        "\n",
        "input_images = np.array(images)\n",
        "input_masks = np.array(encoded_masks)"
      ],
      "metadata": {
        "id": "UZtfEVnnwq7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def convert_rgb_to_grayscale(rgb_image):\n",
        "    return np.dot(rgb_image[...,:3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "input_images = input_images / 255.0"
      ],
      "metadata": {
        "id": "fSNXB7_as-Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title splitting into training and testing\n",
        "split_ratio = 0.7\n",
        "split_index = int(len(input_images) * split_ratio)\n",
        "\n",
        "train_images = input_images[:split_index]\n",
        "train_masks = input_masks[:split_index]\n",
        "\n",
        "val_images = input_images[split_index:]\n",
        "val_masks = input_masks[split_index:]\n",
        "\n",
        "split_ratio2 = 0.5\n",
        "split_index2 = int(len(val_images) * split_ratio)\n",
        "\n",
        "print(split_index2)\n",
        "validation_images = val_images[:split_index2]\n",
        "validation_masks = val_masks[:split_index2]\n",
        "\n",
        "test_images = val_images[split_index2:]\n",
        "test_masks = val_masks[split_index2:]"
      ],
      "metadata": {
        "id": "T2fcd4FrtDih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert grayscale masks to one-hot encoded format\n",
        "num_classes = 3\n",
        "train_masks_encoded = np.zeros((len(train_masks), 512, 512, num_classes), dtype=np.float32)\n",
        "validation_masks_encoded = np.zeros((len(validation_masks), 512, 512, num_classes), dtype=np.float32)\n",
        "\n",
        "test_masks_encoded = np.zeros((len(test_masks), 512, 512, num_classes), dtype=np.float32)\n",
        "\n",
        "for i in range(len(train_masks)):\n",
        "    train_masks_encoded[i] = tf.one_hot(train_masks[i], num_classes)\n",
        "\n",
        "for i in range(len(validation_masks)):\n",
        "    validation_masks_encoded[i] = tf.one_hot(validation_masks[i], num_classes)\n",
        "\n",
        "for i in range(len(test_masks)):\n",
        "    test_masks_encoded[i] = tf.one_hot(test_masks[i], num_classes)"
      ],
      "metadata": {
        "id": "CeiC3PXwtKXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(input_images[0])\n",
        "plt.imshow(train_masks_encoded[0])"
      ],
      "metadata": {
        "id": "zK2KhPHctQfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks_encoded[0].shape"
      ],
      "metadata": {
        "id": "VgZQaQzzxp1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title UNet model\n",
        "def conv_block(input, num_filters):\n",
        "    conv = tf.keras.layers.Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    conv = tf.keras.layers.Activation(\"relu\")(conv)\n",
        "    conv = tf.keras.layers.Conv2D(num_filters, 3, padding=\"same\")(conv)\n",
        "    conv = tf.keras.layers.BatchNormalization()(conv)\n",
        "    conv = tf.keras.layers.Activation(\"relu\")(conv)\n",
        "    return conv\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    skip = conv_block(input, num_filters)\n",
        "    pool = tf.keras.layers.MaxPool2D((2, 2))(skip)\n",
        "    return skip, pool\n",
        "\n",
        "def decoder_block(input, skip, num_filters):\n",
        "    up_conv = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    conv = tf.keras.layers.Concatenate()([up_conv, skip])\n",
        "    conv = conv_block(conv, num_filters)\n",
        "    return conv\n",
        "\n",
        "def unet_model(input_shape, num_classes=3):\n",
        "    inputs = tf.keras.layers.Input(input_shape)\n",
        "\n",
        "    skip1, pool1 = encoder_block(inputs, 64)\n",
        "    skip2, pool2 = encoder_block(pool1, 128)\n",
        "    skip3, pool3 = encoder_block(pool2, 256)\n",
        "    skip4, pool4 = encoder_block(pool3, 512)\n",
        "\n",
        "    bridge = conv_block(pool4, 1024)\n",
        "     decode1 = decoder_block(bridge, skip4, 512)\n",
        "    decode2 = decoder_block(decode1, skip3, 256)\n",
        "    decode3 = decoder_block(decode2, skip2, 128)\n",
        "    decode4 = decoder_block(decode3, skip1, 64)\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(decode4)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "gv-ZZocFxqZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_model((512, 512, 3))\n",
        "max_norm = 1.0\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(clipvalue=max_norm)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JSWKLx73x1Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 4\n",
        "unet_history = model.fit(train_images, train_masks_encoded, validation_data=(validation_images, validation_masks_encoded),\n",
        "          batch_size=batch_size, epochs=epochs)"
      ],
      "metadata": {
        "id": "aivCFiC6yCqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('unet1-football-asma.h5')"
      ],
      "metadata": {
        "id": "X1rQjQg8yEjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(unet_history.history[\"accuracy\"])\n",
        "plt.plot(unet_history.history[\"val_accuracy\"])"
      ],
      "metadata": {
        "id": "dhsvdDRCyG2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(unet_history.history[\"loss\"])\n",
        "plt.plot(unet_history.history[\"val_loss\"])\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(('training loss','val_loss'),loc='upper right')"
      ],
      "metadata": {
        "id": "WPOUBJfXyKJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loss, validation_accuracy = model.evaluate(validation_images, validation_masks_encoded, batch_size = 4)"
      ],
      "metadata": {
        "id": "fuf4oZFjyKna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images, test_masks_encoded, batch_size = 4)"
      ],
      "metadata": {
        "id": "HBUDsJUnyMoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = unet_history.history['accuracy'][-1]\n",
        "print(f'Model Accuracy on the Training Dataset: {round(train_accuracy * 100, 2)}%')\n",
        "print(f'Model Accuracy on the Validation Dataset: {round(validation_accuracy * 100, 2)}%')\n",
        "print(f'Model Accuracy on the Test Dataset: {round(test_accuracy * 100, 2)}%')"
      ],
      "metadata": {
        "id": "zj_kfvBbyO12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_mask = model.predict(test_images[0])"
      ],
      "metadata": {
        "id": "LqDQCUNmyQwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet_predict = model.predict(test_images)"
      ],
      "metadata": {
        "id": "hDsE7DcvyU0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_result(og, unet,  target):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(10,5))\n",
        "    axs[0].set_title(\"Original\")\n",
        "    axs[0].imshow(og)\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    axs[1].set_title(\"U-Net Predicted Mask\")\n",
        "    axs[1].imshow(unet)\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    axs[2].set_title(\"Ground Truth\")\n",
        "    axs[2].imshow(target)\n",
        "    axs[2].axis('off')"
      ],
      "metadata": {
        "id": "FhMLE_knyWu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_test_idx = random.sample(range(47), 3)\n",
        "for idx in show_test_idx:\n",
        "    show_result(test_images[idx], unet_predict[idx], test_masks[idx])"
      ],
      "metadata": {
        "id": "MykV5jFHyZGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_test_idx"
      ],
      "metadata": {
        "id": "XB4G7ql4ybqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Field Lines extraction\n",
        "\n",
        "def detectLinesCircles(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    lower_green = np.array([35, 50, 50])\n",
        "    upper_green = np.array([90, 255, 255])\n",
        "\n",
        "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "    blurred_mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
        "\n",
        "    edges = cv2.Canny(mask, 50, 150)\n",
        "\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=100)\n",
        "\n",
        "    side_list = []\n",
        "    for line in lines:\n",
        "        rho, theta = line[0]\n",
        "\n",
        "        slope = np.tan(theta)\n",
        "\n",
        "        if slope < -3 and slope > -100:\n",
        "            side = \"Left\"\n",
        "        elif slope > 3 and slope < 100:\n",
        "           side = \"Right\"\n",
        "        elif (slope<0.5 and slope>- 0.5) or slope < -100 or slope > 100:\n",
        "            side = \"Center\"\n",
        "        else:\n",
        "            if slope<0:\n",
        "                side = 'Right'\n",
        "            else:\n",
        "                side = 'Left'\n",
        "        #print(side)\n",
        "        #print('slope ', slope)\n",
        "        side_list.append(side)\n",
        "\n",
        "        a = np.cos(theta)\n",
        "        b = np.sin(theta)\n",
        "        x0 = a * rho\n",
        "        y0 = b * rho\n",
        "        x1 = int(x0 + 1000 * (-b))\n",
        "        y1 = int(y0 + 1000 * (a))\n",
        "        x2 = int(x0 - 1000 * (-b))\n",
        "        y2 = int(y0 - 1000 * (a))\n",
        "        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Hough circle transform to detect circles\n",
        "    '''circles = cv2.HoughCircles(blurred_mask, cv2.HOUGH_GRADIENT, dp=0.1, minDist=150, param1=60, param2=30, minRadius=0, maxRadius=0)\n",
        "\n",
        "    if circles is not None:\n",
        "        circles = np.round(circles[0, :]).astype(int)\n",
        "\n",
        "        filtered_circles = []\n",
        "        for (x, y, r) in circles:\n",
        "            if mask[y, x] != 0:\n",
        "                filtered_circles.append((x, y, r))\n",
        "\n",
        "        for (x, y, r) in filtered_circles:\n",
        "            cv2.circle(image, (x, y), r, (0, 255, 0), 2)'''\n",
        "\n",
        "    isCenter = any(item in 'Center' for item in side_list)\n",
        "\n",
        "    if isCenter:\n",
        "        field_side = 'Center'\n",
        "         else:\n",
        "        sorted_lines = [item for items, c in Counter(side_list).most_common()\n",
        "                                  for item in [items] * c]\n",
        "        field_side =  sorted_lines[0]\n",
        "\n",
        "    return image, field_side"
      ],
      "metadata": {
        "id": "9iPBYHL9ygnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id = 400\n",
        "test_img = images[id].copy()\n",
        "test_img, field_side = detectLinesCircles(test_img)\n",
        "\n",
        "field_side"
      ],
      "metadata": {
        "id": "Zrn1y0tfy6Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(test_img)"
      ],
      "metadata": {
        "id": "_xClcDqBy9fd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}